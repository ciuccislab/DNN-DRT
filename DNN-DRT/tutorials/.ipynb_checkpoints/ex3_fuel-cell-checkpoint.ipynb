{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aef91b7b",
   "metadata": {},
   "source": [
    "# Deconvolution of electrochemical impedance spectroscopy data using the deep-neural-network-enhanced distribution of relaxation times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a22145",
   "metadata": {},
   "source": [
    "In this tutorial, we will show how two use the DNN-DRT model to analyze the synthetic EIS data generated with the \"hook\" model (Section 3.2.2.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfa115f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the librairies needed\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy as cp\n",
    "import sys\n",
    "from torch import nn\n",
    "import math\n",
    "from math import pi, sin, cos, sqrt, log\n",
    "import compute_DRT\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb55941b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# check the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**2,3), 'MB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**2,3), 'MB')\n",
    "    \n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86467151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot standards\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif', size=15)\n",
    "plt.rc('xtick', labelsize=15)\n",
    "plt.rc('ytick', labelsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41acc292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "357644be",
   "metadata": {},
   "source": [
    "# 1. Experimental data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc7504a",
   "metadata": {},
   "source": [
    "## 1.1 Define the ranges of frequencies and timescales, and import the EIS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2fbf068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load of the data\n",
    "df = pd.read_csv('EIS_fuel-cell-hook.csv')   \n",
    "N_f = df.shape[0]\n",
    "freq_vec = df['Freq/Hz'].to_numpy().reshape(N_f,1)\n",
    "Z_re = df['Re(Z)/mohm cm2'].to_numpy().reshape(N_f,1)\n",
    "Z_im = -df['Minus Im(Z) / mohm cm2'].to_numpy().reshape(N_f,1)\n",
    "Z_exp = Z_re + 1j*Z_im # experimental impedance spectrum\n",
    "\n",
    "# # define tau range\n",
    "log_tau_min = -4\n",
    "log_tau_max = 4\n",
    "\n",
    "# tau's for ridge regression\n",
    "N_tau_RR = 10*int(log_tau_max-log_tau_min)+1\n",
    "tau_vec_RR = np.logspace(log_tau_min, log_tau_max, num = N_tau_RR, endpoint=True).reshape(N_tau_RR,1)\n",
    "log_tau_vec_RR = np.log(tau_vec_RR)\n",
    "# during pretraining the ANN will take the normalized log of the tau_RR vector as input\n",
    "# for consistency with the NN implementation we will compute the L1 matrix using the following\n",
    "# normalized log(tau) vector\n",
    "log_tau_vec_RR_norm = -1.+2.*(log_tau_vec_RR-log_tau_vec_RR.min())/(log_tau_vec_RR.max()-log_tau_vec_RR.min())\n",
    "\n",
    "# the NN will use a much more finer grid, consistent with differential programming\n",
    "# so the tau's of the NN, are far more\n",
    "N_tau_NN = 10*int(log_tau_max-log_tau_min)+1\n",
    "tau_vec_NN = np.logspace(log_tau_min, log_tau_max, num = N_tau_NN, endpoint=True).reshape(N_tau_NN,1)\n",
    "log_tau_vec_NN = np.log(tau_vec_NN)\n",
    "# the ANN will take the normalized log10 of the tau vector as input\n",
    "log_tau_vec_NN_norm = -1.+2.*(log_tau_vec_NN-log_tau_vec_NN.min())/(log_tau_vec_NN.max()-log_tau_vec_NN.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54522298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2197b866",
   "metadata": {},
   "source": [
    "## 1.2 Define the parameters of the equivalent circuit model (ECM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f86c28f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_inf = 65.\n",
    "\n",
    "# ZARC 1\n",
    "R_ct_1 = 345.\n",
    "phi_1 = 0.65\n",
    "tau_1 = 1E-2\n",
    "\n",
    "# ZARC 2\n",
    "R_ct_2 = -140. # this enforces the hook\n",
    "phi_2 = 0.75\n",
    "tau_2 = 1E1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32123b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7324b890",
   "metadata": {},
   "source": [
    "## 1.3 Define the ECM impedance described with the hook model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22805c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECM impedance\n",
    "T_1 = tau_1**phi_1/R_ct_1\n",
    "T_2 = tau_2**phi_2/R_ct_2\n",
    "\n",
    "Z_ECM = R_inf + 1./(1./R_ct_1+T_1*(1j*2.*pi*freq_vec)**phi_1) \\\n",
    "                  + 1./(1./R_ct_2+T_2*(1j*2.*pi*freq_vec)**phi_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b83dd58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0be95e40",
   "metadata": {},
   "source": [
    "## 1.4 Define the ECM DRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2fee445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first DRT\n",
    "gamma_ECM_RR_1 = (R_ct_1)/(2.*pi)*sin((1.-phi_1)*pi)/(np.cosh(phi_1*np.log(tau_vec_RR/tau_1))-cos((1.-phi_1)*pi))\n",
    "gamma_ECM_NN_1 = (R_ct_1)/(2.*pi)*sin((1.-phi_1)*pi)/(np.cosh(phi_1*np.log(tau_vec_NN/tau_1))-cos((1.-phi_1)*pi))\n",
    "# second DRT\n",
    "gamma_ECM_RR_2 = (R_ct_2)/(2.*pi)*sin((1.-phi_2)*pi)/(np.cosh(phi_2*np.log(tau_vec_RR/tau_2))-cos((1.-phi_2)*pi))\n",
    "gamma_ECM_NN_2 = (R_ct_2)/(2.*pi)*sin((1.-phi_2)*pi)/(np.cosh(phi_2*np.log(tau_vec_NN/tau_2))-cos((1.-phi_2)*pi))\n",
    "# total gamma\n",
    "gamma_ECM_RR = gamma_ECM_RR_1 + gamma_ECM_RR_2\n",
    "gamma_ECM_NN = gamma_ECM_NN_1 + gamma_ECM_NN_2\n",
    "\n",
    "# normalized gamma\n",
    "R_ct = R_ct_1 + R_ct_2\n",
    "gamma_ECM_RR_norm = gamma_ECM_RR/R_ct\n",
    "gamma_ECM_NN_norm = gamma_ECM_NN/R_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd1e717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "060da653",
   "metadata": {},
   "source": [
    "## 1.5 Nyquist plot of the experimental and ECM impedances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4550c2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAGMCAYAAAAV9pyMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABUHElEQVR4nO3deXycZb3//9ckbdMFmukEWYoFOimiX0EgC4geBc0ElGNZJJMKcqQqyQh69ACSGJejfF1CAi4gCDMBEVGxmSm0ha9bpiDHnyynnQEEAZFM2QQFmkxSlpS2uX9/3J0hk1kydzKTzPJ+Ph55lNz3dc9cd27a+eS6PtfnshmGYSAiIiIiWauY6w6IiIiIFBsFUCIiIiIWKYASERERsUgBlIiIiIhFCqBERERELFIAJSIiImKRAigRERERixRAiYiIiFikAEpERETEonlz3YFciUQieL1eotEokUgEu91OT08PTqczoV00GqW7u5uamhoABgcH6enpwW63T6udiIiIlJ+SCKAikQg9PT14vd74sc7OTmpraxkcHEwIopqamujr66Ouri5+bX19PaFQKCE4yradiIiIlJ+SmMLr6emhp6cn6ZjdbsftdseP+Xw+gHhQBOB0Oqmrq6O7u9tyOxERESlPJRFA9ff309bWlnTc5XIRDofj3/v9fhoaGpLaNTY2EggELLcTERGR8lQSAVSqYCeVYDBIbW1t0nGn00kkEiEajVpqJyIiIuWpJHKgBgYGUh4Ph8Px/KdMQU8spykSiSQlnadrN3F6T0RERMpLSQRQqQSDQSKRSDy4GhoaAsiYAD40NBQ/P1W7dHbu3MnOnTvj34+PjzM0NERNTQ02my37GxAREZFZZRgGO3bsYPny5VRUZJ6kK9kAyuPx0NHRgcvlmrJttlNy2bTr7u7msssuy+r1REREpPA899xzvP3tb8/YpiQDKLfbjcvlSliZ53A4gNRBUGxEyeFwZN0una6uLi6++OL49yMjIxxyyCE899xzLF261PK9iIiIyOwYHR1lxYoV7LvvvlO2LbkAqre3F6fTmVTWIJvaTU6nM+t26VRVVVFVVZV0fOnSpQqgREREikA2KTclsQovJlZiYGLwNLGMgcvlYnBwMOm6aDSaEDxl205ERETKU8kEUOFwmEgkQkdHR8LxYDAY/2+3253wfczAwAAtLS2W24mIiEh5shmGYcx1J2YqEongdrtZs2ZNwvHt27cTDocTyhzU1tbi9XrjyeWRSITm5uakEads201ldHSU6upqRkZGNIUnIiJSwKx8ZpdEDlRzczORSCRhui5m8ohRKBSis7OTcDiM3W4nFAqlrCOVbTsREREpPyUxAlXINAIlIiJSHKx8ZpdMDpSIiIjIbFEAJSIiImKRAigRERERixRAiYiIiFikAEpERETEIgVQIiIiIhYpgBIRERGxSAGUiIiIiEUKoEREREQsUgAlIiIiYpECKBERERGLFECJiIiIWDRvrjsgIiJSFsbGwO+HDRtg+3aoqYEzzgC3GxYunOveiUUKoERERPJt0yZYuxaGh6GiAsbHzT9vuw2+9CW4+WZYvXqueykWaApPREQknzZtMkeaolHz+/HxxD+jUTj9dLOdFA0FUCIiIvkyNmaOPAEYRuo2seNr15rtpSgogBIREckXv9+ctksXPMUYhtkuEJidfsmMKYASERHJlw0bzFynbFRUwO2357U72YhEIng8Hnw+H52dnXR2dsbP9fb2Ul9fj81mY9myZQSDQQACgUD8WHNzM9FolGAwSHNzM8uWLaO3txefz0dvby+dnZ243e74tcXKZhhThcUyE6Ojo1RXVzMyMsLSpUvnujsiIjKbTjoJ7rnHWvu7785Xb6YUDodpampi27Zt2O12ADo7O4lEIvj9/ng7j8dDMBhkcHAwfqy+vp7NmzfHr4tZtmwZDoeDgYEBnE4nYAZp9fX19PX10dLSkvf7ypaVz2yNQImIiORLTY21ESiHI7/9mYLb7aa9vT0hCOrq6iIQCBCJROLHvF4vdrsdj8cDmCNTqYInAIfDQUtLSzx4AnA6nXR1ddHW1kY0llxfZBRAiYiI5MsZZ7y12m4q4+Nw5pl57U4mkUiESCRCY2NjwnG73Y7dbiccDicc9/v99Pf34/F4qKurSxk8xdTU1CQda2lpiU/1FSPVgRIREckXt9us8xSNZk4kt9nAboc5nM6KBUhbtmxhaGgo4VxPTw91dXUJx5xOJz09PXg8noQ8qWw59o62TRzZKiYKoERERPJl4UKzSObpp5tBUqogymYz/7z55jmtSB6bYmtubsblcmV1zeDgIO3t7TQ3NyfkQ2UjFjhNnNorJprCExERyafVq83VeLEprlhOVOxPux02bpzzSuSxabiBgYGkc9FoNGkKr7Ozk56enqR8qFS2b9+edCwYDGK327MO1gqNAigREZF8O+00eOEFuOUWMy/qpJPMP2+5xTxeINu4bN68GZ/PlzSt1t3dnTBS1NnZmZAr5ff78fl8+Hy+lK8bmFTfKhKJ0N3dTV9fX8bcqUKmMgZ5pjIGIiJSTCKRCD09PdTW1mK324lGo/GVeZ2dnfEVeS0tLfHSBj6fLz4C1dLSgsfjiY8s1dbW0tLSQm1tLQ6Hg0gkwuDgIJ2dnQU3fWflM1sBVJ4pgBIRkXJWW1uLx+Oho6NjrrsyJdWBEhEREckjBVAiIiKSV6mSyIudAigRERHJuXA4jNvtJhKJEAgEMq7SK0bKgcoz5UCJiIgUB+VAiYiIiOSRAigRERERixRAiYiIiFikAEpERETEIgVQIiIiIhYpgBIRERGxSAGUiIiIiEUKoEREREQsUgAlIiIiYpECKBERERGL5s11B0RERGTuRaNR2traiEQihMNhnE4nLpcrfn5oaIhIJEIkEiEajTI4OIjT6Uz5Wj6fD7/fj91ux+FwYLfbaWxspKWlJb43XkdHBwAej4etW7cSDoepq6sjFApl7Gc4HKa+vh6AlpYWmpubaW9vz9FPIXsKoERERAS73Y7f748HKC0tLfT09CS1i0Qi8U2CJwdQsXMNDQ3xAComGAzS29vLunXrEgIzr9dLJBKhs7OTQCAQD6TS2bp1K06nE6fTid/vn/mNT5Om8ERERCQuFvTU1NSkPO90Ounp6SESiSQcj0Qi1NbWsmbNGrxeb0LwBOByuXC5XITD4aTXdDgcNDc3Y7fb8Xq9GfvncDiyv5k80giUiIjIJG1tbTz66KNz3Y1pOfLII+nr68vre7hcLjo7OxOOud1u6urq4lNzqdTV1aWdbnM4HLS3t+Pz+dIGUYFAgJaWlqT3ngsKoERERCZ59NFHuf/+++e6GwXF5/MlBD/Nzc0J58Lh8JSjR2AGWgMDAynPeTweent744HSZENDQ9PoeX5oCk9ERESmNDm5e2IeUywXaeKxdFwuF2vWrEl5zul0UldXlzIQi0QiNDQ0WOlyXpVcADUxOz+V+vp6fD5ffO42GAzS3NycNJcbjUbp7Oykt7eX3t5ePB4P0Wg0n10XEREpGOvWrcPj8eDxeOKfnenEPkOzzU/KlCTe1dVFMBhM+lwOBoMZr5ttJTGFFwt2gPhSyHQikQgejyf+fWzVweSVBE1NTfT19cUfViQSob6+nlAolJQYJyIiUmrWrFkTz2eKRCIJU3b5FJu683q9KVcBFoqSCKAmZu339vZmDKBcLheNjY1s376dxsZGXC5XUkAUi7InRrqxYcXu7u6CfqAiIjJzRx555Fx3Ydry0Xen05kw+ADm4EXs89PpdBKJRBgaGsrJIEMsmTz2eRsMBmltbZ3x6+ZSSQRQVjidzowrBMCcy001z9rY2FjwEbGIiMxcvlexFaPJSd39/f20trZit9txu90Eg0GCweCURS2j0Sj9/f0Z23k8Hnw+H8FgEJfLRSQSySq/ajaVXA5ULgSDQWpra5OOxyJs5UKJiEi5mZzqMjg4GB9tam9vT5v8PVkwGJwyGbyurg6n04nX6yUajaateD6Xyi6Aikaj+Hy++JfH40lIVMsUHMX+R5mc2DbRzp07GR0dTfgSEREpNZPTZWJVzDMlmwNs2bIlKRl8aGgoqURBrDK5z+cruNEnKMMpvKGhofiQIyQmhzudzvgDzDSHm6kORXd3N5dddlkuuywiIjJrYgMJ27dvT9vG7XYnfU46nU4GBwdxu90MDg7S1dWV0CYSieD1eunq6kp6vUgkwuDgYMKx1tZWPB5Pxn7MpbILoCbvm+N0OmloaMDj8aQt7BWTzdRdV1cXF198cfz70dFRVqxYMa2+ioiIzJbYivZgMAiYVb8nf+5FIhG2bt1KNBpNmQ/sdDoJhUL4fL54kOVwOKitrcVut6e8JpY/FY1GCYfD9PT0UFdXh91up729PSF5vbe3ly1btsQ3NXa73dpMeC45nc74kGOshkWqYCk28pSpzkVVVRVVVVW576SIiEgeZbMPXbba29uzDmoybQg8uT9TLQKbTWWVAxUrEZ/OxCWZmRRiMpuIiIjMnrIKoPr7+5PmWIF43YpY8ORyuVK2i60EUCFNERGR8lZWAVR7e3vK4cnJdSti87GTDQwMpNzcUERERMpLyQVQmbL1U03h9fb24nA4EhLbYsHUxCAqlrCmIpoiIiJSMknksSz9/v5+AJqbm3E6nbjd7nj9CKfTSUtLS3zfvFjOU6rpulAoRGdnJ+FwGLvdTigUmnKVnoiIiJQHm2EYxlx3opSNjo5SXV3NyMgIS5cunevuiIiISBpWPrNLbgpPREREJN8UQImIiIhYpABKRERExCIFUCIiIiIWKYASERERsUgBlIiIiIhFCqBERERELFIAJSIiImKRAigRERERixRAiYiIiFikAEpERETEIgVQIiIiIhYpgBIRERGxSAGUiIiIiEUKoEREREQsUgAlIiIiYpECKBERERGLFECJiIiIWKQASkRERMQiBVAiIiIiFimAEhEREbFIAZSIiIiIRQqgRERERCxSACUiIiJikQIoEREREYsUQImIiIhYpABKRERExCIFUCIiIiIWKYASERERsUgBlIiIiIhFCqBERERELFIAJSIiImKRAigRERERixRAiYiIiFikAEpERETEIgVQIiIiIhYpgBIRERGxSAGUiIiIiEUKoEREREQsmtUA6qGHHprNtxMRERHJixkFUKOjo1xwwQXU1NRQWVlJZWUlxx13HDfeeGPK9oZhcMUVV3DKKafwiU98YiZvLSIiIjJnbIZhGNO58KGHHqKpqYnh4eHkF7XZWLZsGX19fZx55plJ530+HxdccAF79uyZzlsXldHRUaqrqxkZGWHp0qVz3R0RERFJw8pn9rRGoB588EHq6upYtmwZXq+XUCjE8PAwg4OD+P1+Lr30UqqrqznrrLNobGzk4YcfTri+pqZmOm8rIiIiUhCmNQLV0NCAy+Xi8ssvz9guHA7j9Xrx+/00NzfT19fH0qVLWb9+Pa2trRqBEhERkYJh5TPbcgC1fv16BgYGuP766y11av369axbtw6bzYZhGAQCAcbHxy29RjFSACUiIlIc8hpAXXDBBfT09MwoGBgZGWFoaIiVK1dO+zWKhQIoERGR4mDlM3ue1Rc3DGPGgUB1dTXV1dUzeg0RERGRuWI5gKqtrc1HP3ImHA7T1tZGKBRKeT4ajdLd3R1PZB8cHKSnpwe73T6tdiIiIlJ+LAdQQ0ND+ejHjESjUTo7OwHYunUr4XA4bdumpib6+vqoq6sDIBKJUF9fTygUSgiOsm0nIiIi5cdyGYNoNJqHbsyM3W7H6/Xi9XpZs2ZN2nY+nw8gHhQBOJ1O6urq6O7uttxOREREypPlAMowjBltyfLQQw9xww03cOWVV077NabL7/fT0NCQdLyxsZFAIGC5nYiIiJQnywFUR0cHbW1tlq656667aG1t5ZRTTmHr1q0YhhGfcptNwWAwZQ6X0+kkEonER9eybSciIiLlyXIAFZvKesc73sEzzzyTtt3TTz9NV1cXNTU1eDwe1qxZw+9//3vOP/98HA7HjDo9HZmCnlhO01TB0cR26ezcuZPR0dGELxERESktlpPIAXp7e6mrq8PpdNLc3Myxxx4bH7EZHBwkGAwSDocxDIOenh4uvfTSnHZ6OmLJ75kSwIeGhuLnp2qXTnd3N5dddtl0uigiIiJFYloBVHV1NYODg7jd7nhl8phYXc729nZ6enpS1nvasmXLNLubH9lOyWXTrquri4svvjj+/ejoKCtWrJhmz0RERKQQTSuAivH7/QSDQQKBAJFIBLvdTmNjI+3t7SkDpyuuuCI+etPf3z+Tt7YsNm2YKgiK9cnhcGTdLp2qqiqqqqpm2FsRKXc7duzgxRdfZGhoiNHRUUZGRhJSAyZ/v2PHDnbv3s2ePXum/DIMg4ULF2b1ZbfbcTgc1NTUJHw5HA6WLVvGvHkz+hgRKVoz/j/f5XLhcrmyajuXU3nZ1G5yOp1ZtxMRmY6xsTG2bdvG888/z4svvpj267XXXpvrrmbFbrdTU1PDQQcdxIoVKzjkkEM45JBDEv7bbrdjs9nmuqsiOVVWvzq4XC4GBweTjkej0YTgKdt2IiKpvPrqqwwODvLUU0/Fv2LfP//881jcgrSgRaNRotFoyn8zY/bZZ594QHXooYdyxBFH8K53vYt3vetdHHLIIVRUWF7PJDLnyiqAcrvd9PT0JB0fGBigpaXFcjsRKW+vvfYajzzyCH/5y194+OGHeeSRR3jyySf517/+NdddKyivvvoqjz/+OI8//njSucWLF3PEEUfwzne+Mx5Uvetd7+Lwww9nwYIFc9BbkezYjCx/Ferr68Pn8/GJT3yCtra2GW8onC+dnZ309vam/Q2vtrYWr9cbn3aMRCI0Nzcn/faUbbupWNnZWUQKk2EYPP300/FAKfbn4OBgSY0mFZJ58+Zx1FFHUV9fT0NDAw0NDRx11FEKqiSvrHxmZx1AAWzevBmv10sgEKC5uRmPx8PHP/7xGXc4FzweD2Amp0ejUVwuF06nE7fbnZCjFds3r7a2FrvdTigUorOzMymvKdt2U1EAJVJ8otEoDzzwAPfddx/33XcfDzzwACMjI3PdrSSLFy9m6dKlLF26lH333ZcFCxZQWVlJpc1G5fbtVL7yCpW7dlFZVUXlQQdRuWIFlXsDkJ1vvMHYM88w9uKLjL35JmM2G2OLFjE2fz5jO3cy9uqrvP7GG+yZ43ucaMGCBRx11FHxgKq+vp4jjzyS+fPnz3XXpETkLYCaaP369Xi9XjZv3kxLSwsej4cPf/jD0+pwKVMAJVLYxsfHefLJJ7nvvvu49957ue+++3jsscdmfWTJ4XBw0EEHJX3tv//+VFdXs3Tp0vifsa+UK+A2bYK1a2F4GCoqYHz8rT+XLYObbwbDyNzmwgvhe9/DMAx2AEPA9glf8e8bGti+dSsvA88DzwKvzs6PK27hwoWccMIJnHjiiZx44okcf/zxLFq0aJZ7IaViVgKomJGREfr7+/F6vWzbto3W1lY8Hg/HHHPMTF62ZCiAEikshmHwxBNPEAwGCQaD/OlPf2J4eDiv71lRUcGhhx7KqlWrqK2tZdWqVRx22GEsX76cgw46iAMPPJCFCxfC2Bj4/bBhA2zfDjU1cMYZ4HbDwoXmi2Vq84c/mP9t3mhyR2w283hsRVymf/5jbTOZ9DoGMIIZSD23989ngefmz+fZ8XGe2bOH5/a2y5cFCxZw/PHHc+KJJ/LBD36Q973vfSxZsiSP7yilZFYDqIm2bdtGIBDA6/UyPDxMe3s7Ho+Hww47LFdvUXQUQInMvRdeeIHNmzfHg6YXXnghL++zYsUKjjzySA4//HBWrVoV/zr00EOnzt2Z6ciR3Q67dsHrr08d+MyhN4AngceBJ/b++fjeYzvz8H7z5s2joaGBpqYmTj31VI4//ngqKyvz8E5SCuYsgJooHA7T39+Pz+eL74fX3t5edkGEAiiR2ff6669z1113EQwGGRgY4LHHHsvp6y9cuJAjjzySo48+mve85z0cffTRHHXUUVPv85lu9GjRImhtNdvMdOSoSO0BtmEGVX8FHgS2AtaW7UzNsWQJH/nYxzh19WpOOeUU9ttvvxy/gxSzggigJgoGg/h8vnjyudvtprW1tSwCCgVQIrPjpZde4s4772Tjxo0MDAzwxhtv5OR1Fy9ezHHHHcd73/tejjnmGI4++mhWrVplvQJ3phGmEg6MZmoICGMGU6G9fz6do9e22Wy8973v5dSTT+bUykqOefBBKoaGUk+dSlkouABqosnJ52vWrCmYlXz5oABKJH+efPJJNm7cyMaNG7n33ntzkvi9cuVKTjjhBN73vvdxwgkn8J73vCf7YGm6I0xiySuYwdQDwP8A92JODc7UQcBZgNtm4/2GQWVs6nT16hy8uhSDgg6gYlIln7vd7pJbyacASiR3DMPgoYceYt26dWzcuJEnnnhiRq9ns9mor6/npJNOigdMBx54YOrGUyV4a4RpzrwJbAHu2fv1Z2CmG+HEgqlW4P23307FGWdkl+QvRa0oAqiJRkZG8Pl88eTzrq4uvvzlL891t3JCAZTIzP3973/n1ltv5Ve/+hV/+9vfZvRaq1atiu/h+aEPfWjqvCWYOsF777J/oLyCpGxX88U2lx8ZmZWfzy7Mab9YQPVH4PUZvN5BNhstH/kI7j/9ife/+qq59UyqJP/mZgVYRa7oAqiJwuEwoVCItra2ue5KTiiAEpmef/zjH6xbt45bb72VrVu3Tvt19ttvP5qamuJBU9pVwTOdfstm2X+xSXdPscDpa1+D737X/O9M7TZuNP88/fT0bad6zxkYw5zq+83er7/P4LWWA/8BfBo4InYw1uclS+C119KvotRUYMEr6gCq1CiAEsnejh07WLduHb/61a/44x//OO2cpqOOOorTTz+d0047jfr6+rc2q80UJLW3l/70Wzar+WLnvvpV+MlPMpdVWL06u/ILscBhqraf/3zmgCxH/g78FjOY+iPTL59wAmYg1QpUZ2oY+5lu2ACnnTbNd5PZUJQB1NNPP12S9aIUQIlkZhgG999/PzfccAPr1q3jtdesZ69UVlbywQ9+MB40rVy5MrlRpg9vKI0RJJsNFi+G+fMhGp1+JfJY0DM2BoEA3H47DA2BwwFnngktLYlTUtm2y6ZtpueUh1pXrwF3AbcDG4DplFRdBHwcM5j6EFCRqpHNZvb/hRfM+1Q+VUEqygDqggsu4LrrrpvrbuScAiiR1F555RV+8YtfcMMNN/DXv/7V8vWLFy/m1FNP5fTTT+fUU081c5lKdRWclZGjjRvNXJypAhorQc9sy9S3gYHspgKn4U1gM+DHDKii03iNQ4HPAO1AyuUIt9wCS5dmP2ons6ogA6jR0VE6OztT5jJEo1EikQh79hTStpW5oQBK5C3j4+Pcfffd9PX1cfvtt/Pmm29aun7+/Pl85CMf4ZxzzmH16tWJW3SUwiq4WKA005GjUjcLo1SxYKofc2QqavH6+UAL8AXMqT4bmH087jh44AGzUaZAODbdp5GqWVWQAVTr3t/+GhsbsdvtCeeGh4fx+Xw89dRTs9GVWaUASgReffVVfv7zn3P11VdbXkVns9k48cQTOeecczjr3/8dx+bNpTnCBOYH5RtvFO/I0WyaySjVxKTvLAKtN4Eg8HPMYMpqzlQdZiD1CWDRvHmwZ8/UifR2O/h86XPzyilgnkUFGUBdccUVXHrppdM+X6wUQEk527ZtG9dccw033ngjIyMjlq6ts9v5pMPBmiOO4OCzzy6NRO+pRpj0YZg72SS3Q3aB1gTDwK+BmzBrT1nhAM4HLsSc6ptSNlO2SkzPqYIMoPr6+kqmNIEVCqCk3BiGwT333MNVV13Fpk2bGI8laWfBvmQJ/7F7N5/duZOjizHRe6pl/9mMMEnuZDNaN1Wg1dcHbW1mUv6kZ/so8DPgFuAlC92qBNYAncB7ZnJ/sZGqSATuuEPTfDlQkAHU5s2bqamp4Zhjjkl5vquri+7u7tnoyqxSACXlYvfu3axbt47e3l7+8pe/WLr2pHe9i7bmZs68+moWFXqQNJnVZf9SeKYKtO64I+NI1S7gd0AfcCdg5f/ejwJfAT7A3jyp6Vi82JyK1P93M1aQARSYQVIwGKShoSEhDyoajRIMBvn732dS3qwwKYCSUjc2NsZNN93EFVdcwbZt27K+7gDMZd+fsdk4fKoVZoUgm+k35SeVrkwjVbFcKmCbYXAdcAPWSiKcgBlIfYw0ZRCmY+I038knKxk9CwUZQH3uc5+jv78/KXgCM4AKhUJs3759NroyqxRASakaHR3l+uuv54c//CH//Oc/s77uvcCXMPcZm5+vzuWSpt8kJlOA/Ic/JARYr4+P82ubjR8bBg9ZeIv/gxlInYM51Tdj2dYG0ygVUMAB1PXXX5/2/Fe+8hUuv/zy2ejKrFIAJaXmlVde4aqrruKaa64hGo1mdc08zGrNXwKOy2PfckIfMDJdKQIs44wzuPfgg7mmr49AIMDu3buzeql3At8C3ORwRCoVJaMnKMgAav369Zx11llpz4+MjFAd23CyhCiAklIxPDzMlVdeyVVXXZV1tfC3AZ/b+7U8n53LVqZpuL4+jTBJXj3//PP88AtfwLtxI9nW238P8H+B05hBjtRUJldJL2NWPrPnzVKfALNj6Trk9/s5//zzZ7M7IpKF0dFRrrrqKr7//e9nXYrgnUAHcDZQEP8cW5mGO/fcueunlLS3v/3tfH/DBr72y19y7fnnc9XYGFMlrvwFOANoAL4NnEIeAinDMKceAwH9/2/BrI1APfjgg/h8Pux2O42NjUnnu7u72bLFalWNwqcRKClWr7/+Otdeey09PT1Z5yc2AF2Y/+DnddohHdVZkmIxNsZrv/gFP73mGq584gme3Zldec73A73A+3Ldn4oKM6l8/fpcv3JRKcgpPIfDQTQaTUogjxkZGdFWLiIF4M0338Tn8/Gd73yHf/3rX1ld8yHMwMlFHqcZMlGitxSxXbt28etf/5rvfve7WVfqb6mspGfPHpy57Mh++8G7313WK/QKMoBqaGhIuQ9ezFRJ5sVKAZQUC8MwuP322+ns7Mx6W6XTMAOn9+a1ZylohElK0O7du/nlL3/JZZddllVJkAXAfwJfB+y57EgZ/70qyADqwQcf5Nhjj532+WKlAEqKwQMPPMAll1zCn//856zafwwzsTUvf2OV6C1lbteuXdx00018+9vf5vnnn5+yfQ3mij0POS4NUoYr9AoygJrKbbfdxsc//vG57kbOKYCSQrbtiSfoWruWdbHd4afgwkxkzcuIk6bhRBKMjY3R19fHd7/73aym048ArgJOif3SYbfDrl1ZbZicVpmt0CuIAOrpp5/G4XDEO3DXXXelbRuNRpVELjKLduzYwXfWruVHt93Gm1m0/zfMwOmkXHZC03AiWXn99de5+uqr+d73vseOHTumbN9y8MH8sKODt7e3w8BA5g2Ts3XLLWWxQq8gAiiHw0FtbW08KFISuQIomXuGYfDrX/+aL3/hC7wwNDRl+2OAbnK4dDo2PXfRRfDMMxphErHgpZde4lvf+hZer3fKTbqXLFnCt771Lb70pS8x/7e/Td6GxooyWqFXEAHU5s2bcTgc8bymk08+mT/84Q9p2yuJXCSPxsZ49Ic/5D9/8AP++MorUzY/GPgecC7TLEegcgIiefPYY49x6aWX8pvf/GbKtu9+97u57rrr+EBjY2KV9EcfhSz+LYg76SS4++7pd7pI5DWAuuGGG6ZV8HLbtm2sXLky7XklkYvkx8itt/KtT3+aH+/cyVRjvPtg7sN1EbB4Om+mPCaRWTMwMMAll1zCI488MmXb8847jx/84Ac4HA7zwFlnmcnh2YxG2WxQXw+HHFLyGxHnNYCqqKjg5JNP5ne/+92MOlkuFEDJXDEMg8BXvsIXe3uZaqvfCqAdcyXPAVbeZPJIk0aYRGbVnj178Pl8fPWrX51yb8oDDjiA6667jjPPPNPMafrUp6y9WRmMKOc9gLLZbNTX17N582b23XffGXW21CmAklkzNmaO/GzYwHP/+AcXPv00d2axcufDwNXAu62+3+LF0NwMIyMaYRKZYy+99BIdHR3cfPPNU7ZtbW3lx1dcwf7HHAPR6MxW6EFJlTnIawC1atUqXC4XPp8Ph8NBKBTi0EMPTdl227Zt9PT00NDQQGtra1kGEAqgZFZs2gRr17JneJif2Gx81TB4dYpLDgZ+gLnbu6UE8dg/mhs3ltRvniKl4E9/+hMXXnghjz76aMZ2++23Hz9eu5Y1V16JLTaSPB0lVubAyme25fzQZcuWcf3113P55ZczNDREfX09d6dJLFu5ciXXX389y5Yto6WlhVNOOYUbb7yR0dFRq28rIuls2gRnnMEjw8O8H/jiFMHTfMw8pyeAVrIInmIBU8Xefy7sdgVPIgXqAx/4AOFwmCuvvJJ99tknbbtXXnmFs6+8kjOPP56XYoFC7O94hYXQILYR8bHHmnlVt9xijoaXAcsjUI2NjfHSBIFAgNbWVmw2G4FAwJxXzSAQCNDe3s7IyAj19fX87//+7/R7XiQ0AiU5N2GqjpdfZtd993H57t38X2D3FJeegjld945s30vTdCJF6/nnn8fj8Uy5Wm///ffnxnPP5WNPP/3Woo9nn4Vw2FrJgxLIjbL0mW1Y1NDQkPB9KBQy7Ha7UVFRYVx55ZVTXh8KhQybzWZUVFRYfeuiNDIyYgDGyMjIXHdFSsHGjYaxbJlhgGFUVBiPglEPBlN87Q/GrWCMm78vTv1ls5lfmzbN9R2LyAyMj48bt9xyi7Fs2bIp/5244IILjNdee8288MQTs/u3ItO/Hxs3zum9T4eVz2zLU3iTs/zr6uoIhUIcdthhdHR0cOGFF2a8vq6ujra2NqtvKyJ7p+qIRtkD9I6PUweEprjs08DjwCfIYrpO03QiJcVms3Huuefy2GOPTbld2nXXXUd9fT3hcNgsVWBlKm+i2MTW2rUlPZ03zZ9OIqfTSTgc5phjjsHr9fKRj3wkY/vOzs5cvK1I6RsbM3MKzjjDzC8wDP5uGHwA6ISM27CsAjYDPwUcU73P/PnwwQ+a73PLLWZCqIInkZJx4IEHsn79evx+P/vvv3/adk888QTHH388PfPmTVntPKNYblQgMP3XKHCWc6AqKyszbrnS3NzM5s2baWhoyFjmYKrXKRXKgZJp27uyjuFhsNkwDIObgC8Cr2W4rALoAP4bWDTVe2hFnUjZeeWVV2hra2PDhg0Z231k3jxu2b2b/ab7RkW4BUxeV+EZhpF21R2YlVHb2trYunUrK1eu5JlnnknZrrq62upbi5SPCdN1AMOGQSvwWTIHT+8E7sPcvy5l8KQVdSJlb7/99uO2226jr6+PxYvT7znwu927ORa4d7pvND4Ojz1WstN405rC83g8Gc97vd4pyxzEy8mLyFtTdWedZU6ltbTEUzL/CLwHyDQQbgMuAcLAcekaLV5sFrs76SRN1YmUOZvNxvnnn89DDz1EY2Nj2nbPAycC3wcMm6WKcaYnnoDly+GOO6bb1cJlNUM9toLuggsumLKt3++Pt7/tttsSzq1atcrqWxclrcKTKU1aWRdbybILjK+CYZti5UwtGH/SijoRmaY333zT+PrXv25UVFRk/LfmtIMOMoYPP7ykV+XldRVeKBTi/PPP59e//jWNjY3cddddadu2tLSwdetWli5dSktLC9///vetvp1IaZs0VRerufIPzC1Wvof5L1c6HuBh4N9SndQ0nYhkYf78+Xz729/m7rvvZvny5WnbbXrxRY4zDB5fuvStdIBslOiqPMtJ5BNt27aNQCDA1q1bWbduXdp2kUiE5uZmnn76aTweDz/5yU9YtWoVTz311HTfumgoiVzSGhszh7Yn7UX1e+Bc4JUMl9YANwKnpzo5fz6ccALst58KX4qIJS+99BKf/OQnCQaDadvsu2gRv3zjDVZPZwuYW26Bc8+dYS/zJ6974U3XyMgIH/7wh3nooYdwuVxs3bqV7du3z8ZbzykFUJIkVkn86qth69b44d3At5h61MkF3Awk/Z6oFXUikgN79uzhu9/9Lt/61rdIFyLYbDa+XVXFV8fGst9LswhW5RVkABUTK3Ngs9lUxkDKz8TSBBO8DKwB0q9vNfew6wYuYtLqj9hvgUW8fYKIFJ7Nmzdzzjnn8NJLL6Vt07Lvvvxsxw6WZPui1dXQ1GQGUm53wY2O57WMwUzFyhzMlfr6enw+H5FIBIBgMEhzc3P8+5hoNEpnZye9vb309vbi8XiSqrCLWDI532mvLUA9mYOnlZhLiS9h0l/aefPMlXVaUSciOdbU1EQ4HOa449Ku7SWwYwcnAf/M9kVHRsx9PD/1qeJfnZfPbPZMgsHgnLyv3W5PWFVgt9uNgYGBpHZ1dXVGKBSKfz84OGg4nU5jeHjY0vtpFZ4Yb7xhGDfcYBjz5yetTrkBjAVTrLL7OBjDWlknInPkjTfeMM4777yM/04dCsZfS2B1npXP7FmfwptrbrebxsZGtm/fTmNjIy6XC7vdntDG5/Ph9XoJhUJJ1zqdTnp6erJ+P03hlbk0U3ZvYlYU92a4dD5wJfCfTNjDrgR2OxeR4mMYBldffTWXXHJJ2vSbauA2zBXEWbPZzJXCL7xQENN5Vj6z581SnwqG0+mko6MjYxu/309DQ0PS8cbGRrxer6UASspYbMpukpeBFuB/Mlx6COBnQlFMrawTkTlks9n40pe+xJFHHklraytDQ0NJbUaAU4AbgPOyfeHYnnn/9V/wox8V1b9rs54DVQyCwSC1tbVJx51OJ5FIRLlQMrWxMXPkCRKW+T6CGRRlCp6agK1722GzmV/r18M995h/nntuUf0jIyKlo6mpiQceeIDDDz885fndwFrgCqsv7PUWXU5U2QVQ0WgUn88X//J4PAkJ5JmCo9hU3+SE84l27tzJ6OhowpeUkdiWLB/4gPlb1YTgaRPwPuDpDJd3AL8D3hY7oCKYIlJgVq1axX333ce//VvKEr6A+W9ZJ5lLsiSJRuH0083R+yKQ9ym8ysrKgipXMDQ0RGtra0IwVF9fTygUwul0xoclJ+dFTX6NdLq7u7nsssty2WUpFmnynQzMfaQ6SP+PyRLgJsAdO9DQAF/6kqbqRKQg1dTUMDAwwGc+8xluvfXWlG16gSHgeqAymxc1DHPEfe3agsmJyiSvI1AjIyNpi3DNFb/fnxAcOZ1OGhoaptwgGTKPTsV0dXUxMjIS/3ruuedm0FspGmlKFOwGPg9cSvrg6TDgPvYGTzabmSD+pz9pqk5ECtrChQv5xS9+wde+9rW0bW7ArHG3M9sXjeVEBTJtn14Y8j6FZ5vO7s2zzOl0xsvWOxwOIHWwFBt5irVJpaqqiqVLlyZ8SQkbG4MbbzRHimKLc/fagbnVynUZLv8A8L/AUfBWJfGbb1bgJCJFoaKigu985ztce+21aT/v1wNnAFnvgldRAbffnpsO5lFZ5UB5PB56e3vTno9Goxmn7mKcTmcOeyVFa9MmM+nx/PNh166EUy8AHwR+k+HyzwJBlO8kIsXvwgsv5Je//CXz5qXODPod5i+Ub2TzYuPj8D//Y+aTFvDmw2UVQPX39zM4OJh0fGhoCLvdHg+eXC5XynbRaBSn05lVkCUlLs2UHcATwAnAQ2kutQE/APqABWCWKPjpT1VJXESK2tlnn82mTZtYtGhRyvN/AE4DXs/mxV55peCrlZdVANXe3o7Xm1y6MBgM0t7eHv/e7Xan3Il6YGCAlpaWvPZRikA0CmefnTRlB3A/8G/As2kuXYRZaO4i9k5vx0oUfPrTmrYTkaL30Y9+lIGBgbQDDUFgNVkGUVDQK/PKKoBKNYXX29uLw+FIKI4ZC6YmBlGRSIRIJKIimuVu0yY4+GB4Pfmv///DrMC7Pc2lBwD3YOYCAJqyE5GS9P73v5+77rorbb7wXcCZZJlYHvslde3agpvOK6tK5E6nk5aWFjo7O4G3cp5STdeFQiE6OzsJh8PY7XZCoRADAwOz3WUpJLFpuxQrS3+JWXk3XcGOd2HmQx0GKlEgIiXv2GOP5a677qKpqYnt25N/rfwDcDbQTxaByMSVeeeem/vOTlNe98IbGRnB4XAUVB2o2aa98EpENJp25Ola4AsZLn0/ZhFNR4Ht+SQikm9/+ctfaGpq4pVXXkl5/lzgZrKYDquoMH+BXb8+tx2cxMpndllN4YlMS5ppOwP4LpmDp9OAAfYGT6ASBSJSVt7znvdw991387a3vS3l+V9g1sqbciRnfBwyFLGeCwqgRDKJTdulCJ6+Cnw9w6VtmPVPFoHynUSkbB155JEZE8uvB76TzQvtzLoc56xQACWSzsTVdhMYwMXA5Rku7QK8wDyVKBAR4eijj+a3v/0tS5YsSXn+vzG3s8ro/vsLajWeAiiRVNJM241jDjf/KMOlvcD32FumQCUKREQAeO9738umTZuoqqpKeb4Ns+BmRgW0Gk8BlMhkaabtxoELSL81iw3wYe57x+LFmrITEZnkwx/+MH6/n4qK5PBjD9ACPJju4gLbJ08BlMhEaabtYsGTL81llZjJkG1gBk//+IeCJxGRFFavXs3111+f8txrmItv/pnuYputYPbJy3sAlccqCSK5lWHaLlPwNA9YB5wD5l/uX//aTBoXEZGU2tra+MY3vpHy3POYhTZTTtQZBjz5ZB57lr28BlDV1dV0dHTk8y1EciPDarsvkj54WoC5NctZoGk7ERELLrvsMj796U+nPHc/4CFNeYNHHy2IZPK8FtIUFdIsCmmKZBrAlzE3/k1lAbAB+Ci8NW2nkScRkazt2rWLjxxzDHc99ljK8z/A3Ds0yfz5cP31cM45OV2ko0KaItnKsLfdf5Nl8KRpOxGRaZk/fz7+gQFqUySVA3QAf051Ytcu+OxnYflyuOOOfHYxLQVQUr7STNsBXEH6wm5JI0+athMRmTbH8uXc8eMfk2q8ZzfQCryU7uJoFE4/fU6m9DSFl2eawitQY2Nw0EHmX75JvMDn0lw2DzPnaTVo2k5EJId+e9hh/Pszz6TMe/ow5gbElakuzOE+o5rCE5lKV1fK4Gkd5oq7VCqAW9kbPGnaTkQkpz5aX883Y/uGTnIXGXZ/mKP6UAqgpPwEAvCjHyUd/gPwH6Tf1PJnmEXeNG0nIpIHZ5zBNwyDU9Kc/ibwQLprKypmvT6UAigpL4EAtLYmHd4CfBzYleayazGDKxXJFBHJE7ebimXL+AWwIsXpPcAngR2prh0fh5dfzmfvkiiAkvKxaRO43UlVxp8C/h2zAm4q3cCFoGk7EZF8WrgQbr6Z/Ww21pE632kQ+K90199//6yuyFMAJeVhbAzOOy/p8EvAR4B0v7d8GfgKaNpORGQ2rF4NGzZwwrJl/HeaJj/FTLlIsmvXrK7IUwAl5SFF0vjrmAnhg2kuOQ/oBU3biYjMptNOgxde4Ks+H+9Pk1TeRpqpPIC1a81fmvNMAZSUvhRJ43uAc4H/TXPJqcANgA00bSciMtsWLmReWxu/8PnYJ8XpZ4HOVNfN4oo8BVBS2tIkjXcA6dZrNAL9mDWfuOgijTyJiMyRw84/nys+l7oy33WkWZU3SyvyFEBJ6UqTNH496bdoqQXuBJaAOer0ve/ls4ciIjKF9muv5aTq6pTnPo85o5BgfByGhvLdLQVQUqLGxsx58EmCwBfSXFID/BbYH8wVdz//eU43qRQREesqKiq44fjjWZTiXAjoS3WRcqBEpsnvN+fBJ3gScJPitxWgCtgIHA5m8OT3a+pORKRA1J57Lt9Ic+6rQNJ401/+kvcgSgGUlKZrr034Noq54i6apvlNwPtj3/j9cNZZeeqYiIhY5nZz8aJFvCPFqWHMen0JXn8974nkCqCk9AQC8MBbqYV7gLMxR6BS+dbe84CZNK7gSUSksCxcSNUxx/DjNKd/jLkyL8FPfpLXLimAktISSxyf4GvA79I0/wS8VaxNSeMiIoVrwQJOBj6W4tROSC68ed99eS2qqQBKSsfYGJxzTsKhfqAnTfNGzIq2NlDSuIhIoaupgYoKLid18HILKQoj57GopgIoKR1dXfDaWzva/RX4TJqmB2HWgYqv6lDSuIhIYTvjDBgf593A2hSnx0mRC5XHopoKoKQ0jI3Bj9+aHR8BziT1BsELgNuAg2MHjj9eeU8iIoXO7YZlywAzd3V+iiY3A89MPJDHopoKoKQ0XHop7DELFBiYI09/T9P0J8B7Jx74QrrKUCIiUjAWLoSbbwZgBfDpFE12A1dPPJDHopoKoKT4BQJwzTXxb3+IOcKUyueAz048sGwZtLTkr28iIpI7zc1QWQmYe+FVpmhyI/Bq7BubDRyOvHRFAZQUt0mr7u7F3OculeOBH008YLOZv80ocVxEpDj4/fHZBifmSurJRoBfxL4xDDjzzLx0RQGUFK9Jq+62A2tIXWl8PyCAWXE8TonjIiLFZcMGM69pry+maRavADV/ft5mGRRASfGasOrOwFyV8XyKZjbgVuDtEw/+538qcVxEpNhs327mNe11HObswmSPAA8DHHFE3mYZFEBJcZq06u4q4M40Tb8FuCYeqKyE3t68dU1ERPJkby2oiS5I0/RmgH32yVtXFEBJcerqis+Dh0mf9+TCrESe4ItfVN6TiEgx2lsLaqKzgMUpmv4K2PPwwyqkKRI3NhbfLPg14BxgV4pmB2AmEias0liyRNu1iIgUK7cbFieGS/tgBlGT/Qu4/403VEhTJM7vh11myHQx8LcUTWyYwdMBk0/ceqtGn0REitXChXD00UmHz0nRFGAT5G1TYQVQUnzWrwfMvxi+NE2+wqS8JzB/C9GqOxGR4rZgQdKhDwH7pmi6EfK2qbACKCk+W7fyL+D8NKePAy6bfFCr7kRESkOKRPIq4CMpmv4NeAHysqmwAigpLmNjGP/4B23AyylOLwF+SYo9krTqTkSkNKRIJAf4aJrm/wN52VRYAZQUl64ufgbckeb0j4FVkw8efLDynkRESsWETYUnOjFN83sgL5sKK4CS4jE2xrPXXMN/pTl9JmYxzSQNDfnqkYiIzLYJmwpPtJJJBZP32gp52VRYAZQUDaO/n/N372Y0xbn9AS/m6rsk2ixYRKS0rF4NxyfWILeRuir5o8BugOrqnHZBAZQUjb7LLmMg3TngbalO5HEfJBERmUPHHJN0KLnAAYwBfwc46KCcvr0CKCkOY2P8f5FIylOfAk5Ld90XvqD8JxGRUvTPfyYdShVAwd4A6sUXc/r2CqCkOHR1cTNmccyJqYPLMffBS6myUlXHRURK1VNPJR2qTdP0WYCRkZy+/bycvloJikajdHd3U1NTA8Dg4CA9PT3Y7fa57Vg52bt1iw34JPBhoB1z8+AbAHu667TnnYhIaRobg78l70OxIk3zZwEcjpx2QQHUFJqamujr66Ourg6ASCRCfX09oVBIQdRsmbB1C8BBmFXI7wXen+6aigqNPomIlKquLti9O+nw0r1fkxcbvQhw5pk57YKm8DLw+cyNQmLBE4DT6aSuro7u7u656lb5ue66pEM2MgRPYK7O0OiTiEjp2bQJfvSjtKftKY7tsNlyvqBIAVQGfr+fhhQ1hBobGwnkaXdnmWRsDLZssX7dhRfmvi8iIjK3xsbMbVkySLUn3o7Fi3P+S7UCqAyCwSC1tckpaU6nk0gkQjQanf1OlRu/P+UwbUYqXSAiUpr8fnNblgwWpzg2VlWV864ogEojU3AUy32KpFhWv3PnTkZHRxO+ZAZSTN9NSaULRERK04YNYEtZMjluT4pj896WslLgjCiASmNob8n3TIniQynKwnd3d1NdXR3/WrEi3ZoAmdJ0pu+UPC4iUrr+9S8wjIxNUs1ZzMtxEU1QADUtmUanurq6GBkZiX8999xzs9exUjOd6Tslj4uIlKZNm+D++6ds9mqKY1WLFuW8OypjkIZjb72IVMFSbOTJkaKmRFVVFVV5mGstS9OZvlPyuIhI6dm0Cc44Y8rRJ4CXUhzbf//9c94ljUClkU2NJ6fTmf+OlKtNm+C++6xdM2+eksdFREpNFivvYl4n9QjU2/KQA6URqAxcLheDg4NJx6PRKE6nU4U088XCX5YEjY2avhMRKTVZrLyL2Zbm+IEHHpi7/uylEagM3G43wWAw6fjAwAAtGunIHwt/WRJo+k5EpPRs2GAuEMrCE2mOv+Md78hZd2IUQGXQ3t4OkBBERSIRIpEIPT09c9Wt0jed3KdlyzR9JyJSirZvh/HxrJo+nub4O9/5ztz1Zy9N4U0hFArR2dlJOBzGbrcTCoUYGBiY626VrulWHr/5Zk3fiYiUopoas/ZTFgnkD6Q4tmDBAlauXJnzbimAmoLdbsfr9c51N8rHdEoXnHACrF6dn/6IiMjcWr48q+BpHPhziuP19fXMm5f7cEdTeFJYsqgym0S5TyIipSkQgGuvzarpX4FU2bPvf3/GreenTQGUFJbt27P6TSNOpQtERErTpk3Q2pr1Z8KdaY4rgJLyUFOT9WoLQKULRERKUaycjYVfqDelODa/spIPfehDOevWRAqgpLCccUbWqy0ATd+JiJQii+VsniF1AvlJJ51EdXV1zro1kQIoKSxut1mSIJs8KJUuEBEpTRZqPwH8DEg1VnXaGWfkpj8pKICSwrJwoVmSANIHUTab+aXSBSIipenll7OejRgHbkpxvLKyErfbndNuTaQASgrP6tXmbx+xrXJiv4XE/rTbYeNGlS4QESlFgQDce2/Wze/EnMKb7GMf+xgHHHBAzro1mepASWE67TR44QXzL9Ltt8PQEDgccOaZ5rSdRp5ERErP174G3/uepUvS7Qvymc98Zub9ycBmGFbWjItVo6OjVFdXMzIywtKlS+e6OyIiIoUpEDDzYC34E/DBFMdXrFjB4OAg8+fPt/R6Vj6zNYUnIiIic2tsDD71KUuXGMBX05y75JJLLAdPVimAEhERkbnV1QVvvGHpkg3A/5fiuMPh4Pzzz89FrzJSDpSIiIjMrrExs9bThg3w5JPw6KOWLt8JfCXNuYsvvpglS5bMtIdTUgAlIiIis2fTJrPK+PCwubraSvHkvbqBJ1McX758ORdddNFMe5gVBVAiIiKTxUZI1q+Hv/0NRkdh6VI44gg46ywz2Vmrga3btMnccSJmGsHTX4F06/S+853vsHjx4un0zDKtwsszrcITESkyE0dI0lm2zCzmq3p02Rsbg+XLIRq1tmn8BLuAD5B625Zjjz2WLVu2UFlZOe0uahWeiIjIdMRGSKbah214GE4/3Wwv2YntbzeDcZtvkDp4qqys5IYbbphR8GSVAigREREwR0jWrs3+A94w4OyzzREVmdqGDdntc5rG70hfNPOSSy6hrq5u2q89HQqgRERE4K0REitefx0OPhjuuCM/fSoFY2Nwyy1wzz3THn2KAP+R5tzhhx/ON7/5zWl3b7oUQImIiMD0R0hef13Teels2mTmPX3qU7B9+7ReIgp8DHglxbkFCxawbt26WUscn0gBlIiICJgf8NPNzzEMOOccc7RFTLF8shlMce4CWoHH05z/wQ9+wLHHHjvt158JBVAiIiIANTUzu/6116CjIzd9KXZjY3DeeWZgOc2gdA+wFhhIc/6ss87iwgsvnGYHZ04BlIiICCTWJ5quH//YrB1V7rq6ZjTyNA60LVrEr9KcP/bYY/nZz36GbQZJ6TOlAEpERATM4pi5yKVpaSnvfKhAAH70o2lfPg58Hrgpzd54y5cv54477mCfffaZ9nvkggIoERERMCuL//znuXmtcs2HCgSgtXXal7+Judru+jTnlyxZwh133MHBBx887ffIFQVQIiIiMWedBZ2dM3+d114zK5WXk02bzOBpmjlPO4DVkHbabtGiRdx5552zXu8pHQVQIiIiE11+eW6CqM9/vnzqQ1ktQjrJ88CHgD+kOV9VVcXGjRs56aSTpte/PFAAJSIiMtnll5uFNWeSE7VnD5x2Glx0UelP502nCOle91RWUl9VRSjN+QULFhAIBGhubp5+//JAAZSIiEgqLS1mbaif/hRmssfaj34EBx1UmqNRsSrj0xixM4CrgSbD4KWdO1O22Xffffnd737Hxz72sZn1Mw8UQImIiKSzcCF8+tNw++0ze51o1KxWHgjkpFsFIRAwa2d96lPw4ouWLv0XcDrwJWDP+HjKNgcccAD33HMPH/rQh2bc1XxQACUiIpKBYRiwejV84QszfSEzyboU6kR97Wtm2YfXX7d86UbgKCDTeNw73vEO7r333jmrMp6NeXPdARERkUL2iU98gpUrV/LVb3yDpT/96bSChjjDMKcGjzsORkfNr6VL4YgjzBWAbrc56lVIxsbMHKcNG8wpzbExeOAByy/zMnApMNXaxNWrV3PLLbdQXV09jc7OHpthTHfjH8nG6Ogo1dXVjIyMsHTp0rnujoiIWHDXXXfR1NQEwNve9ja++fGP0+b1siBfb7hsmVn+YPXqfL2DNZs2mavrhoehogLSTLdlsgfwAV/F3Bg4k8suu4yvf/3rVFTMzQSZlc9sBVB5pgBKRKQ47dmzh/r6eh5++OGE484DD+Tb27fziV278pMHY7OZoz2nnZaPV89ebDNgmHZ5gj9j5jmlW2EXs//++3PTTTdx6qmnTut9csXKZ7ZyoERERFL42c9+lhQ8AUT++U8+uWsXx9psrMMcYckpwzBHfeay9MEMNwMOAacC/8bUwdPpp5/OI488MufBk1XKgRIREZlk165dfPOb38zY5i+GwSeAWqAD+BSQs+yl4WH4r/+Cl182845qaszRoOnmSE3OY5r8epPP/+Mf09oM+C/AZcBtWbTdd999ueqqq1i7du2cbgo8XZrCyzNN4YmIFKdHHnmESy65hIGBgazavw34LOABDstVJ2J5R7E/M+VIpQuSFi2C9vbEPKaJr3fhhfCTn0w7z2kP8P+AHwF3Z3lNS0sLP/jBD1ixYoWl98o35UAVEAVQIiLFyzAMfv/73/OVr3wl5XReKjbgo0D73j/zknD+7nfDqlVw4IHwz3/C4CD87W+wa5eZQ2UY2QVDsbbT8BLwS+AaIJLlNYcffjjXXHMNJ5988rTeM98UQBUQBVAiIsVvfHycdevW8fWvf51IJNtwAZYBZwFnAycCM6hnXhBeBzYBtwC/J/v8L7vdTmdnJxdddBFVVVV5699MKYAqIAqgRERKx5tvvsnPf/5zenp6eOqppyxdewDw75ijUs1AYVc5esvLmMHSb4A7gR0Wrt1nn3246KKLuPjii7Hb7fnoXk4pgCogCqBERErPnj17uO222+ju7ubBBx+0fP084H1A094/jwMK5RPiVWAL8D/Ab4H/xdy3zoolCxdywRe+QGdnJ/vtt1+uu5g3CqAKiAIoEZHSZRgGf/zjH7nuuuu4/fbb2b1797RepwI4EjgBOBr4P3u/3paznqY2DPwNeBx4ALgfeASwXi7TdOh++/HFL3+Zz3g8RTHiNJkCqAKiAEpEpDy8+OKL3HjjjfT19fHss8/m5DX3A94JvB1YvvfrYOBAYB9g8d6vJUAVsAt4c++fuzBzll7GTPh+CXMT338CT2IGTi/npJdw4okn8sUvfpHTTjuNefOKt0KSAqgCogBKRKS8jI+P8+c//5lbb70Vv9/PK6+8MtddyosjKir4j//+bz553nkcdthhc92dnFAAVUAUQImIlK9du3axefNmNmzYwG9+8xuee+65ue7SjByBmQh/NlC/cSO2ud5uJscUQBUQBVAiIgJmvtRjjz3Gb3/7W35z553cd++9jO3aNdfdymgh8CHMbVk+arNRaxiFt+FxDimAKiAKoEREJJVdu3bx8MMPc++998a/5nqE6lDgvcAJNhvvNQyOWbSIqmOOgaoqcDjgzDOhpWV628kUAQVQGdTX1+PxeHC5XDidToLBID09PXi9XpxOZ7xdNBqlu7ubmpoaAAYHB+np6bG8qkABlIiIZGtkZITHH3+cxx5+mMc2buSxcJhno1H+sXMn0Ry9xwKbjbcvXswRtbW888QTOeLd7+aIlSt519//zgF33QVDQ2URLKWiACqDZcuWEZ2wQaLdbsfv9+NyuRLa1dfX09fXR11dHQCRSITm5mZCoZClIEoBlIiIzNimTbx+3nm8GI3ygs3Gy4bBG8BrmCvtXgd2AvOB+RUVLNh/f+YfcAAL6urY7+ST2f/tb+eAAw5g//33Z+nSpUW5ee9ssPKZXbxrDafJ5XLR2NjI9u3baWxsxOVyJQVEPp8PIB48ATidTurq6uju7qanp2c2uywiIuXutNNY/OKL1AYC1N5+uzlKVF0NBx0EL74IIyNlO2o0V8ougHI6nXR0dGRs4/f7aWhoSDre2NiI1+tVACUiIrNv4UI491zzS+ZcxVx3oBAFg0Fqa2uTjjudTiKRSMIUoIiIiJSfshuBikaj8Sk6gFAoRGdnZzyBPFNwFJvqi0QiCdN7IiIiUl7KLoAaGhqitbU1IRiqr68nFArhdDoZGhoCyJgoHmuTys6dO9m5c2f8+5GREcBMTBMREZHCFfuszmZ9XdkFUH6/P+F7p9NJQ0MDHo+HgYGBjNdmM3XX3d3NZZddlnR8xYoVlvopIiIic2PHjh1UV1dnbFNUAVQ0GqWpqclSDpLf759yus3pdMan9RwOR/y9JouNPMXapNLV1cXFF1+c0OdDDz2UZ599dsqHUUpGR0dZsWIFzz33XFmVbyjH+y7He4byvO9yvGfQfZfTfRuGwY4dO1i+fPmUbYsqgLLb7YRCoWlf7/F4qK2tTbsKLxqNZlXjaWLBzcmqqqqoqqpKOl5dXV02/wNOtHTpUt13mSjHe4byvO9yvGfQfZeLbAc7ymoVXn9/P4ODg0nHh4aGsNvt8eDJ5XKlbBeNRnE6nZarkYuIiEhpKasAqr29Ha/Xm3Q8GAzS3t4e/97tdhMMBpPaDQwM0NLSktc+ioiISOErqwDK4/HQ29ubcKy3txeHw5FQHDMWTE0MoiKRCJFIxHIRzaqqKr75zW+mnNYrZbrv8rnvcrxnKM/7Lsd7Bt13ud13tspuL7xIJBIfhYrlPKUKiqLRKJ2dndTW1sZzrybWixIREZHyVXYBlIiIiMhMldUUnoiIiEguKIASERERsaio6kAVk2g0Snd3NzU1NQAMDg7S09NTMiUQ6uvr8Xg8uFwunE4nwWCQnp4evF5vQp5Ysf8cwuEwbW1taeuPZXt/xfZzmOq+S+35x3Ijo9EokUgknhs5OeexlJ53tvdcas8a3rr3mpoatm/fTiQSoaurK6nocik+76nuuRSfd94Ykhd1dXVGKBSKfz84OGg4nU5jeHh47jqVQ3a73QDiX3a73RgYGEhqV4w/h+HhYaO9vd1ob2836urqjEx/TbK9v2L4OVi571J6/oODg0Z7e3vCsY6ODgMwBgcHE46XyvO2cs+l9KwNw+xXR0dHwjGv12sACf03jNJ63tnec6k973xSAJUHXq/XqKurSzre0tKS9D9xsWppaTF6enqMjo4Ow+/3p/xLUwo/h56enrSBRLb3V4w/h0z3bRil9fzb29tT9t9utyf0v5Sed7b3bBil9awNw/x/2263J9zH8PCwASQElaX0vLO9Z8MoveedT8qBygO/309DQ0PS8cbGRgKBwBz0KPecTicdHR309PTQ0tKScti21H8O2d5fKf4cSun59/f309bWlnTc5XIRDofj35fS8872nqG0njVAXV1d2nI0sf1OobSed7b3DKX3vPNJAVQeBINBamtrk447nU4ikYilzZCLWan/HLK9v1L/OaRTLPed6oMglVJ63tnec7aK4Z5jXC4XoVAoITCIFU3u6upKOFYqzzvbe85WMdzzbFASeY5l+h8n9j9vJBJJStwrNtFoFJ/PF/9+cqHRUv85ZHt/mQqvFvPPoZSe/8DAQMrj4XDY8v0Uy/PO5p5jSulZpxIMBunu7sbv98f7WGrPe7JU9xxT6s87lxRA5VhsODTTSoTJQ6bFaGhoiNbW1oS/MPX19YRCIZxOZ8n/HLK9v9j5Uvs5lPrzDwaDRCKReKBRDs978j3HlOqzDofDBINBtmzZgsvlwuVyxc+V6vPOdM8xpfq880FTeLOolIY1/X5/wl8gp9NJQ0MDHo9nymtL6eeQSrb3V8w/h1J//h6Ph46OjpQfMJOVyvNOd8+l+qzr6uro6OjA7/dTW1vLypUriUQiU15XzM87m3su1eedDwqgcszhcACp/0eKReWxNqUmVjMESv/nkO39lfrPYaJSef5utxuXy5WwR2apP+9U95xJqTzrmNgG8m63Gyj95w3J95xJqT3vXFEAlWPZFBEr9g2JPR4Pvb29ac/HNmmeSjH/HLK9v1L8OZTy8+/t7cXpdMY3HI8p5eed7p6htJ/1ZA0NDYTDYUv3VOz3PvGeobyedy4ogMoDl8vF4OBg0vFoNJr1X7pC1t/fn/L+YjkBsfsr9Z9DtvdXaj+HUn3+seXXE0dhJi7pL8XnPdU9l+Kzrq2tTTnqMjHnB0rreWd7z6X4vPNJAVQeuN3u+HDnRAMDA7S0tMxBj3Krvb095W+rwWAwPiwMpf9zyPb+Su3nUIrPPxwOE4lE6OjoSDg+sf+l9ryzuedSfNaRSCTlFFMscIytHiul553tPZfi886rua7kWaqcTmdC+ftYmftSMDg4aPT09CQc6+npSXl/xf5ziG1vkU6291dsP4dM911qz39wcNCoq6szenp6Er46OjoMl8uV0LZUnne291xqz9owzP5P3r5kYGDAAAyv15twvFSed7b3XIrPO59UxiBPYrUzwuEwdrudUCiUtvZKsXE6nbS0tNDZ2Qm8NS+eaki3WH8OsRUn/f39ADQ3N+N0OuPJtjHZ3l+x/Byyue9Se/7Nzc1EIpGkCtxA0m/TpfK8s73nUnvWAB0dHQQCAbxeL3a7nejezZQHBgaSViCWyvPO9p5L8Xnnk80wDGOuOyEiIiJSTJQDJSIiImKRAigRERERixRAiYiIiFikAEpERETEIgVQIiIiIhYpgBIRERGxSAGUiIiIiEUKoEREREQsUgAlIiIiYpECKBGRWeDz+ea6CyKSQwqgRETyLBgMptzlXkSKlzYTFpGSEA6Hqa+vTzjmdDoBsNvt8WOxjVQBvF4v7e3tee+b1+tlzZo1GdtEIhF6enoAs781NTXxTVybm5uTNjYWkbmlzYRFpCR4PB58Ph9OpxOv15uwy3yqdi6Xa9Z2j7fZbAwPDycEcjHRaJTOzk62bt1KX18fdXV1ls6LyNxQACUiJWHZsmW0trZmnCrr7e2ls7OTuro6QqHQrPQrEAjg9XrTBmu1tbUA8dGmdDo7O+nt7SUUCimIEikACqBEpOhFIhHcbnfGoCgQCOB2u7Hb7Wzbti3laFA+NDc34/F4Uk7Bud1uAoEAg4OD8enGTGpraxkaGprV/otIakoiF5GiFwgE4vlDqYTD4XjwFAqFZi34iEajBIPBlMFTMBgkEAjgcrmyCp7AHIWKTemJyNxSACUiRW/Lli1pc54ikQhNTU0A+P3+rIOVXOjv70+b/O33+wEsTcc1NDTEX1dE5pYCKBEperFgZLJoNEpzczPRaBS/3582yMoXr9eLx+NJeS62EjCWA5WNWPAXjUZn3DcRmRkFUCJSspqamuLlAWa7DEAkEiESiaQN2qYzjTg0NDTDXolIriiAEpGS1NzcTDgcpr29nY6Ojll//0AgQGtra9rzjY2NwNSr7yYKh8OAtWk/EckPBVAiUnI8Hg/BYBCXyzVnFcAzTd8B8QKewWAw69fcsmULQMbXFZHZoTIGIlJS5qLW02ThcJimpiaGh4cztosV9bRaxmCq1xWR/NMIlIiUjEAgQGdnJ3a7nc2bN6dsE0vezqd169ZltUVMrPRCNqNk4XCYSCRCX1/fjPsnIjOnESgRKQmxvfBitZ7Sjeh4PJ68T+stW7YsYx8m6u3tpbu7O6vRqq1bt87ZqJqIJNIIlIgUvWxrPQUCgaQNh3MtGAzicDiyrjfV0dGBw+GYMheqv79fo08iBUQBlIgUNSu1nrxeb8LKuGAwSH19PTabjUgkQm9vL263G5/Pl9Cmt7cXn8+Hx+OJr4TL9B5Wk7x7enoyjorFKpZr9Z1IATFERIpYXV2dARg9PT0Z2/n9fsPlciUdHx4eTri+o6PDaG9vj19TV1eX0N5utxuDg4Np3wcwhoeHp+z35P6m6ltMS0tLwmuGQiEjFApN+R4ikj8agRKRopVtradwOExbWxtutzvp3OSClhNHg9ra2ujq6ko439ramnbfvdhIUTZFMrdv357wvdvtzji6NfE1g8GgRqNE5ti8ue6AiMh0ZFPrKVaFPDYll6mw5eSAJBwOE41Gk47X19enfT+v15sySEuns7MzXlATYOvWrUnvF9u2JRAIAGY18oGBgTkpDioib1EAJSJFJxgMxoOirVu3Ju0nNzQ0lLRfXF1dXcaRIYfDkfD91q1b4+818ZzD4Ug5AhWNRgkGg2n35ZussbExKdhK9bpDQ0MEAoF4AAXM+rY0IpJMAZSIFB2Xy4WR5wossVV0LpcrqxV1/f39tLS0ZL3HXUtLS1b34HQ6836vImKdcqBERFKI5TKlyktKVXLA6/WyZs2a2eiaiBQABVAiImn09fXR2dmZcCwSiSRND0ajUSKRiKbWRMqIpvBEpGwFg8GEFXculyshD6mlpQWn04nH44kX4HQ4HEmBks/ny5igLiKlR1u5iIjMUG1tLV6vN2MRTxEpLQqgRERmIBwO09TUNOVediJSWpQDJSIyA1u3bk0qtikipU8jUCIiIiIWaQRKRERExCIFUCIiIiIWKYASERERsUgBlIiIiIhFCqBERERELFIAJSIiImKRAigRERERixRAiYiIiFj0/wNBnPfKSwaTpgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 647.2x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.real(Z_exp), -np.imag(Z_exp), 'o', markersize=8, color='red', label='exp')\n",
    "plt.plot(np.real(Z_ECM), -np.imag(Z_ECM), linewidth=4, color='black', label='ECM')\n",
    "\n",
    "plt.axis([0,400,-50,200])\n",
    "plt.xticks(np.arange(0, 400, step=50))\n",
    "plt.legend(frameon=False, fontsize = 15)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.xlabel('$Z_{\\\\rm re}/\\\\Omega$', fontsize = 20)\n",
    "plt.ylabel('$-Z_{\\\\rm im}/\\\\Omega$', fontsize = 20)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(6.472, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f1328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e20c22eb",
   "metadata": {},
   "source": [
    "# 2. Ridge regression (RR) to prepare the pretraining step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b57480",
   "metadata": {},
   "source": [
    "## 2.1 Conduct RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51df5a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "Z_RR = np.zeros(2*N_f)\n",
    "Z_RR[:N_f] = Z_exp.real.flatten()\n",
    "Z_RR[N_f:] = Z_exp.imag.flatten()\n",
    "\n",
    "# matrices\n",
    "A_re_RR = compute_DRT.compute_A_re(freq_vec, tau_vec_RR)\n",
    "A_im_RR = compute_DRT.compute_A_im(freq_vec, tau_vec_RR)\n",
    "L2_RR = compute_DRT.compute_L2(log_tau_vec_RR_norm)\n",
    "L1_RR = compute_DRT.compute_L1(log_tau_vec_RR_norm)\n",
    "\n",
    "# build matrices for cvxpy\n",
    "lambda_0 = 1.0E-3\n",
    "A_R0 = np.zeros((2*N_f,1))\n",
    "A_R0[0:N_f,0] = 1.0\n",
    "A_RR = np.hstack( ( A_R0, np.vstack((A_re_RR, A_im_RR)) ) )\n",
    "L1_RR = np.hstack( ( np.zeros((N_tau_RR-1,1)), L1_RR ) )\n",
    "Q = A_RR.T@A_RR + lambda_0*L1_RR.T@L1_RR\n",
    "q = -2.*A_RR.T@Z_RR\n",
    "\n",
    "# Define and solve the CVXPY problem.\n",
    "x_RR = cp.Variable(N_tau_RR+1)\n",
    "prob = cp.Problem(cp.Minimize(cp.quad_form(x_RR, Q) + q.T @ x_RR)) # , [x_RR >= 0]) # we do not need a positive gamma anymore \n",
    "prob.solve();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e2fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a569ce81",
   "metadata": {},
   "source": [
    "## 2.2 Plot of the DRT recovered with RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66fc618",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(tau_vec_RR, gamma_ECM_RR, linewidth=4, color='black', label= 'ECM')\n",
    "plt.semilogx(tau_vec_RR, x_RR.value[1:], linewidth=4, color='red', label='DRT') \n",
    "\n",
    "plt.xlim(1E-4, 1E4)\n",
    "plt.legend(frameon=False, fontsize = 15)\n",
    "plt.xlabel('$\\\\tau/\\\\rm s$', fontsize=20)\n",
    "plt.ylabel('$\\\\gamma/\\\\Omega$', fontsize=20)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(6.472, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d71184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f46e7b30",
   "metadata": {},
   "source": [
    "# 3. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3281680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zexp on Rct_RR\n",
    "R_inf_RR = x_RR.value[0]\n",
    "R_ct_RR = np.trapz(x_RR.value[1:], log_tau_vec_RR.flatten())\n",
    "Z_exp_norm = (Z_exp-R_inf_RR)/R_ct_RR\n",
    "\n",
    "# gamma on Rct_RR\n",
    "gamma_RR = x_RR.value[1:].reshape(N_tau_RR,1)\n",
    "gamma_RR_norm = gamma_RR/R_ct_RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86c302e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57183735",
   "metadata": {},
   "source": [
    "# 4. Pretraining of the deep neural network (DNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dfa727",
   "metadata": {},
   "source": [
    "## 4.1 Prepare the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "465d3147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma from RR and its normalization\n",
    "gamma_RR_torch =  torch.from_numpy(gamma_RR).type(Tensor)\n",
    "gamma_RR_norm_torch =  torch.from_numpy(gamma_RR_norm).type(Tensor)\n",
    "\n",
    "# gamma ECM for the NN (we will used it to compute the distances)\n",
    "gamma_ECM_NN_torch = torch.from_numpy(gamma_ECM_NN).type(Tensor)\n",
    "\n",
    "# torch vectors\n",
    "\n",
    "# log(tau) used for pretraining and full training\n",
    "log_tau_vec_RR_norm_torch = torch.from_numpy(log_tau_vec_RR_norm).type(Tensor)\n",
    "log_tau_vec_NN_norm_torch = torch.from_numpy(log_tau_vec_NN_norm).type(Tensor)\n",
    "\n",
    "# log(tau) used for the integration error computation\n",
    "log_tau_vec_NN_torch = torch.from_numpy(log_tau_vec_NN).type(Tensor)\n",
    "\n",
    "# Z_exp used for inversion\n",
    "Z_exp_re_norm_torch = torch.from_numpy(np.real(Z_exp_norm)).type(Tensor)\n",
    "Z_exp_im_norm_torch = torch.from_numpy(np.imag(Z_exp_norm)).type(Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e366878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "303eb7b2",
   "metadata": {},
   "source": [
    "## 4.2 Define the DNN (Section 2.5.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "993599a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10657\n"
     ]
    }
   ],
   "source": [
    "class gamma_elu_layer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(in_features, out_features, bias=True)        \n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "        nn.init.uniform_(self.linear.bias)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.elu(self.linear(input))\n",
    "    \n",
    "class gamma_sine_layer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(in_features, out_features, bias=True)        \n",
    "        nn.init.xavier_normal_(self.linear.weight)\n",
    "        nn.init.zeros_(self.linear.bias)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return torch.sin(self.linear(input))\n",
    "    \n",
    "class gamma_softplus_layer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(in_features, out_features, bias=True)        \n",
    "        nn.init.xavier_normal_(self.linear.weight)\n",
    "        nn.init.zeros_(self.linear.bias)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.softplus(self.linear(input))\n",
    "    \n",
    "class gamma_net(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = []\n",
    "        self.net.append(gamma_sine_layer(in_features, hidden_features))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            # self.net.append(gamma_elu_layer(hidden_features, hidden_features))\n",
    "            self.net.append(gamma_elu_layer(hidden_features, hidden_features))\n",
    "\n",
    "        self.net.append(gamma_elu_layer(hidden_features, out_features))\n",
    "        \n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output, coords\n",
    "    \n",
    "# let's define the model gamma\n",
    "model_gamma = gamma_net(in_features=1, out_features=1, hidden_features=32, hidden_layers=10)\n",
    "\n",
    "if cuda:\n",
    "    model_gamma.cuda()\n",
    "print(compute_DRT.count_parameters(model_gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3422e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbbf0084",
   "metadata": {},
   "source": [
    "## 4.3 Pretraining step (Section 2.5.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d82ac53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=0; loss=4.358390e+01\n",
      "iter=200; loss=2.305932e-02\n",
      "iter=400; loss=1.296019e-02\n",
      "iter=600; loss=8.222500e-03\n",
      "iter=800; loss=5.296643e-03\n",
      "iter=1000; loss=3.677631e-03\n",
      "iter=1200; loss=5.962479e-03\n",
      "iter=1400; loss=2.141641e-03\n",
      "iter=1600; loss=2.606418e-03\n",
      "iter=1800; loss=1.659819e-02\n",
      "iter=2000; loss=2.081777e-03\n"
     ]
    }
   ],
   "source": [
    "def loss_pretrain_fn(x, gamma):\n",
    "\n",
    "    MSE = torch.sum((x - gamma)**2)\n",
    "    \n",
    "    return MSE\n",
    "\n",
    "learning_rate = 1e-3\n",
    "max_iters = 2001\n",
    "optimizer = torch.optim.Adam(model_gamma.parameters(), lr=learning_rate)#, weight_decay=1E-5)\n",
    "\n",
    "# numpy arrays where solved data will be saved\n",
    "loss_pretrain_store = np.array([])\n",
    "gamma_NN_pretrain_store = np.zeros((N_tau_RR, max_iters+1))\n",
    "\n",
    "# pretrain torch\n",
    "gamma_NN_pretrain_torch, coords = model_gamma(log_tau_vec_RR_norm_torch)\n",
    "loss_pretrain = loss_pretrain_fn(gamma_NN_pretrain_torch, gamma_RR_norm_torch)\n",
    "\n",
    "# store\n",
    "# gamma from NN\n",
    "gamma_NN_pretrain_store[:, 0] = gamma_NN_pretrain_torch.detach().cpu().numpy().flatten()\n",
    "# loss and store first value\n",
    "loss_pretrain_store = np.append(loss_pretrain_store, loss_pretrain.item())\n",
    "\n",
    "for t in range(max_iters):\n",
    "\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    gamma_NN_pretrain_torch, coords = model_gamma(log_tau_vec_RR_norm_torch)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = loss_pretrain_fn(gamma_NN_pretrain_torch, gamma_RR_norm_torch)\n",
    "    \n",
    "    # set grads to zero\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward pass: compute gradient of the loss with respect to model parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # the step function of the Optimizer updates the NN parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # save loss\n",
    "    loss_pretrain_store = np.append(loss_pretrain_store, loss.item())\n",
    "    \n",
    "    # store gamma\n",
    "    gamma_NN_pretrain_store[:, t+1] = gamma_NN_pretrain_torch.detach().cpu().numpy().flatten()\n",
    "    \n",
    "    # and print it\n",
    "    if not t%200:\n",
    "        print('iter=%d; loss=%e' % (t, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b49647f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b047220",
   "metadata": {},
   "source": [
    "## 4.4 Plot of the ECM, RR-recovered, and DNN-pretrained DRTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373599a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(tau_vec_RR, gamma_ECM_RR_norm, linewidth=4, color='blue', label= 'ECM')\n",
    "plt.semilogx(tau_vec_RR, gamma_RR_norm, linewidth=4, color='black', label='DRT-RR') \n",
    "plt.semilogx(tau_vec_RR, gamma_NN_pretrain_torch.detach().cpu().numpy().flatten(), 'o', color='red', label='DRT-NN pretrain') \n",
    "plt.xlim(1E-4, 1E4)\n",
    "plt.xticks(fontsize=15) \n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(frameon=False, fontsize = 15)\n",
    "plt.xlabel('$\\\\tau/\\\\rm s$', fontsize=20)\n",
    "plt.ylabel('$\\\\gamma/\\\\Omega$', fontsize=20)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(6.472, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abba6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48fafec4",
   "metadata": {},
   "source": [
    "# 5. Training of the DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaecd8c",
   "metadata": {},
   "source": [
    "## 5.1 Prepare the training and define the training loss given in (9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb0247",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gamma_NN_pretrain_torch\n",
    "\n",
    "# data used in NN is transformed to a pytorch tensor\n",
    "A_re = compute_DRT.compute_A_re(freq_vec, tau_vec_NN)\n",
    "A_im = compute_DRT.compute_A_im(freq_vec, tau_vec_NN)\n",
    "\n",
    "A_re_torch = torch.from_numpy(A_re).type(Tensor)\n",
    "A_im_torch = torch.from_numpy(A_im).type(Tensor)\n",
    "\n",
    "def first_derivative(y, x):\n",
    "    grad_outputs = torch.ones_like(y)\n",
    "    first_derivative_out = torch.autograd.grad(y, [x], grad_outputs=grad_outputs, create_graph=True)[0]\n",
    "    return first_derivative_out\n",
    "\n",
    "def second_derivative(y, x):\n",
    "    first_derivative_out = first_derivative(y, x)    \n",
    "    second_derivative_out = first_derivative(first_derivative_out, x)    \n",
    "    return second_derivative_out\n",
    "\n",
    "Delta_log_tau = abs(log_tau_vec_NN_norm[2]-log_tau_vec_NN_norm[1]).item()\n",
    "beta = 0.5\n",
    "alpha = beta*Delta_log_tau\n",
    "print(alpha)\n",
    "\n",
    "def loss_fn(R_inf, gamma, log_tau_norm, A_re, A_im, lambda_0, alpha, Z_re, Z_im):\n",
    "    \n",
    "    MSE = 0.0     \n",
    "    MSE_re = torch.sum((R_inf + torch.matmul(A_re,gamma) - Z_re)**2)\n",
    "    MSE_im = torch.sum((torch.matmul(A_im,gamma) - Z_im)**2)\n",
    "\n",
    "    MSE_D1 = torch.sum(1/alpha*torch.clamp(-gamma[1:]*gamma[:-1], 0, alpha) )\n",
    "    MSE_D2 = torch.sum(2/alpha*torch.clamp(-gamma[2:]*gamma[:-2], 0, alpha/2) )\n",
    "    MSE_D = MSE_D1 + MSE_D2\n",
    "    \n",
    "    grad = first_derivative(gamma, log_tau_norm).flatten()\n",
    "    zeta = 1/(4*(lambda_0**2))\n",
    "    lambda_delP = 1/zeta*(torch.sqrt(grad.detach()**4+2*zeta)-grad.detach()**2)\n",
    "    MSE_der = torch.trapz(lambda_delP*grad**2,log_tau_norm.detach().flatten())\n",
    "\n",
    "    MSE = MSE + MSE_re + MSE_im + MSE_D + MSE_der # MSE\n",
    "    return MSE\n",
    "\n",
    "print(compute_DRT.count_parameters(model_gamma))\n",
    "\n",
    "# saving the model for  earlystop, min loss, and optimal\n",
    "check_Early_stop = 0\n",
    "t_min_loss_loop = 0\n",
    "distance_opt = np.inf\n",
    "\n",
    "learning_rate = 1e-4\n",
    "max_iters = 50001\n",
    "optimizer = torch.optim.Adam(model_gamma.parameters(), lr=learning_rate)#, weight_decay=1E-5)\n",
    "R_inf_torch = torch.tensor([0.0], requires_grad=True, device=\"cpu\").type(Tensor)\n",
    "optimizer.add_param_group({'params': R_inf_torch})\n",
    "print(compute_DRT.count_parameters(model_gamma))\n",
    "\n",
    "# we will store key neural network results here\n",
    "loss_store = np.array([])\n",
    "distance_store = np.array([])\n",
    "gamma_NN_store = torch.zeros((N_tau_NN,max_iters+1)).type(Tensor)\n",
    "R_inf_store = torch.zeros(max_iters+1).type(Tensor)\n",
    "\n",
    "# the gamma is stored here\n",
    "gamma_NN_norm, coords = model_gamma(log_tau_vec_NN_norm_torch)\n",
    "gamma_NN_store[:, 0] = gamma_NN_norm.detach().flatten()\n",
    "    \n",
    "loss = loss_fn(R_inf_torch, gamma_NN_norm, coords, A_re_torch, A_im_torch, lambda_0, alpha, Z_exp_re_norm_torch, Z_exp_im_norm_torch)\n",
    "\n",
    "loss_store = np.append(loss_store, loss.item())\n",
    "R_inf_store[0] = R_inf_RR + R_ct_RR*R_inf_torch[0].detach().item()\n",
    "\n",
    "squared_distance = torch.trapz((R_ct_RR*gamma_NN_norm.detach().T-gamma_ECM_NN_torch.T)**2,log_tau_vec_NN_norm_torch.T)\n",
    "distance_store = np.append(distance_store, sqrt(squared_distance.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b1f6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e661768d",
   "metadata": {},
   "source": [
    "## 5.2 Training step (Section 2.5.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01da85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(max_iters):\n",
    "\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    gamma_NN, coords = model_gamma(log_tau_vec_NN_norm_torch)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = loss_fn(R_inf_torch, gamma_NN, coords, A_re_torch, A_im_torch, lambda_0, alpha, Z_exp_re_norm_torch, Z_exp_im_norm_torch)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # save loss\n",
    "    loss_store = np.append(loss_store, loss.item())\n",
    "        \n",
    "    # store gamma\n",
    "    gamma_NN_store[:, t+1] = R_ct_RR*gamma_NN.detach().flatten()\n",
    "    \n",
    "    # save distance\n",
    "    squared_distance = torch.trapz((R_ct_RR*gamma_NN.detach().T-gamma_ECM_NN_torch.T)**2,log_tau_vec_NN_norm_torch.T)\n",
    "    distance_store = np.append(distance_store, sqrt(squared_distance.item()))\n",
    "    \n",
    "    # save of the optimal model\n",
    "    distance_loc = sqrt(squared_distance)\n",
    "    if distance_loc<distance_opt:\n",
    "        torch.save(model_gamma.state_dict(), './results/model_gamma_opt.pth')\n",
    "        Iter_Opt = t+1\n",
    "        distance_opt = distance_loc\n",
    "    \n",
    "    # store R_inf\n",
    "    R_inf_store[t+1] = R_inf_RR + R_ct_RR*R_inf_torch[0].detach().item()\n",
    "\n",
    "    # and print it\n",
    "    if not t%200:\n",
    "        print('iter=%d; loss=%e' % (t, loss.item()))\n",
    "        \n",
    "gamma_0 = gamma_NN_pretrain_store[:,-1]*R_ct_RR\n",
    "Z_re_pretrain = x_RR.value[0] + A_re_RR@gamma_0\n",
    "Z_im_pretrain = A_im_RR@gamma_0\n",
    "Z_pretrain = Z_re_pretrain + 1j*Z_im_pretrain\n",
    "\n",
    "iter_opt = np.argmin(distance_store)\n",
    "iter_min_loss = np.argmin(loss_store)\n",
    "iter_guess = 2000\n",
    "\n",
    "gamma_opt = gamma_NN_store[:,iter_opt]\n",
    "gamma_min_loss = gamma_NN_store[:,iter_min_loss]\n",
    "gamma_guess = gamma_NN_store[:,iter_guess]\n",
    "\n",
    "Z_re_opt = R_inf_store[iter_opt] + torch.matmul(A_re_torch,gamma_opt)\n",
    "Z_im_opt = torch.matmul(A_im_torch,gamma_opt)\n",
    "Z_opt = Z_re_opt.cpu().numpy()+ 1j*Z_im_opt.cpu().numpy()\n",
    "\n",
    "Z_re_min_loss = R_inf_store[iter_min_loss] + torch.matmul(A_re_torch,gamma_min_loss)\n",
    "Z_im_min_loss = torch.matmul(A_im_torch,gamma_min_loss)\n",
    "Z_min_loss = Z_re_min_loss.cpu().numpy()+ 1j*Z_im_min_loss.cpu().numpy()\n",
    "\n",
    "Z_re_guess = R_inf_store[iter_min_loss] + torch.matmul(A_re_torch,gamma_guess)\n",
    "Z_im_guess = torch.matmul(A_im_torch,gamma_guess)\n",
    "Z_guess = Z_re_guess.cpu().numpy()+ 1j*Z_im_guess.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94afff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4c2efde",
   "metadata": {},
   "source": [
    "## 5.3 Plot of the ECM, DNN-pretrained, and DNN-trained DRTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aadbecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(tau_vec_RR.flatten(), gamma_ECM_RR.flatten(), linewidth=4, color='red', label= 'ECM')\n",
    "plt.semilogx(tau_vec_RR.flatten(), x_RR.value[1:], linewidth=2, color='green', label='pretrain') \n",
    "plt.semilogx(tau_vec_NN.flatten(), gamma_opt.cpu().flatten(), '-', linewidth=2, color='blue', label='opt') \n",
    "\n",
    "plt.xlim(1E-7, 1E3)\n",
    "plt.legend(frameon=False, fontsize = 15)\n",
    "plt.xlabel(r'$\\tau/\\rm s$', fontsize=20)\n",
    "plt.ylabel(r'$\\gamma/\\Omega$', fontsize=20)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(6.472, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecabc0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "355b4ae4",
   "metadata": {},
   "source": [
    "## 5.4 Nyquist plot of the experimental, ECM, DNN-pretrained, and DNN-trained impedances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8cdd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.real(Z_exp), -np.imag(Z_exp), 'o', markersize=8, color='red', label='exp')\n",
    "plt.plot(np.real(Z_ECM), -np.imag(Z_ECM), linewidth=4, color='black', label='ECM')\n",
    "plt.plot(np.real(Z_pretrain), -np.imag(Z_pretrain), linestyle=':', linewidth=4, color='green', label='pretrain')\n",
    "plt.plot(np.real(Z_opt), -np.imag(Z_opt), linewidth=4, color='blue', label='opt')\n",
    "\n",
    "plt.legend(frameon=False, fontsize = 15, loc='upper right')\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "plt.xlabel(r'$Z_{\\rm re}/\\Omega$', fontsize = 20)\n",
    "plt.ylabel(r'$-Z_{\\rm im}/\\Omega$', fontsize = 20)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(6.472, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8519554d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d07dbec5",
   "metadata": {},
   "source": [
    "## 5.5 DNN loss and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e22192",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel(r'iter', fontsize=20)\n",
    "ax1.set_ylabel(r'$\\mathcal{L}$/$\\Omega^2$', color=color, fontsize=20)\n",
    "ax1.plot(loss_store, linewidth=4, color=color)\n",
    "ax1.plot(iter_opt, loss_store[iter_opt], 'o', color='black')\n",
    "ax1.plot(iter_min_loss, loss_store[iter_min_loss], 's', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "plt.axis([0,2E4,0,3E6])\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel(r'$\\varepsilon_\\gamma$/$\\Omega$', fontsize=20, color=color)\n",
    "ax2.plot(distance_store, linewidth=4, color=color)\n",
    "ax2.plot(iter_opt, distance_store[iter_opt], 'o', color='black')\n",
    "ax2.plot(iter_min_loss, distance_store[iter_min_loss], 's', color='blue')\n",
    "plt.plot(np.array([iter_early_stop[1], iter_early_stop[1]]), np.array([0, 4]), \n",
    "              ':', linewidth=3, color=\"red\")\n",
    "plt.plot(np.array([iter_opt, iter_opt]), np.array([0, 4]), \n",
    "              ':', linewidth=3, color=\"blue\")\n",
    "plt.axis([0,2E4,0,4])\n",
    "ax2.tick_params(axis='y', which='minor', labelcolor=color)\n",
    "ax2.tick_params(axis='y', which='major', labelcolor=color)\n",
    "plt.setp(ax2.get_yminorticklabels(), visible=False)\n",
    "\n",
    "plt.text(3800, 2.5, r'early stopping', \n",
    "         {'color': 'red', 'fontsize': 20, 'ha': 'center', 'va': 'center', \n",
    "          'rotation': 90, \n",
    "          'bbox': dict(boxstyle=\"round\", fc=\"white\", ec=\"red\", pad=0.2)})\n",
    "\n",
    "plt.text(6000, 2, r'optimal', \n",
    "         {'color': 'blue', 'fontsize': 20, 'ha': 'center', 'va': 'center', \n",
    "          'rotation': 90, \n",
    "          'bbox': dict(boxstyle=\"round\", fc=\"white\", ec=\"blue\", pad=0.2)})\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "fig.set_size_inches(6.472, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b16b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
